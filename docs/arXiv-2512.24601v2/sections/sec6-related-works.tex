\textbf{Long-Context LM Systems.} There have primarily been two orthogonal directions for long-context management in language model systems: 1) directly changing the architecture of and retraining the base LM to handle longer contexts~\citep{press2022trainshorttestlong, gu2022efficientlymodelinglongsequences, munkhdalai2024leavecontextbehindefficient}, and 2) building a scaffold around the LM that implicitly handles the context -- \RLM{}s focus on the latter. One popular class of such strategies is \textit{lossy} context management, which uses summarization or truncation to compress the input context at the cost of potentially losing fine-grained information. For example, MemWalker~\citep{chen2023walkingmemorymazecontext} constructs a tree-like data structure of the input that the LM can navigate when answering long context questions. ReSum~\citep{wu2025resumunlockinglonghorizonsearch} is another work that adds a summarization tool to periodically compress the context of a multi-turn agent. Another class of strategies implement an explicit memory hierarchy in the agent scaffold~\citep{packer2024memgptllmsoperatingsystems, chhikara2025mem0buildingproductionreadyai,zhang2025gmemorytracinghierarchicalmemory}. \RLM{}s differ from these works in that all context window management is implicitly handled by the LM itself. 


\textbf{Task Decomposition through sub-LM calls.} Many LM-based agents~\citep{guo2024largelanguagemodelbased, anthropic_claude_code_subagents} use multiple, well-placed LM calls to solve a problem; however, many of these calls are placed based on human-engineered workflows. Several methods like ViperGPT~\citep{surismenon2023vipergpt}, THREAD~\citep{schroeder2025threadthinkingdeeperrecursive}, DisCIPL~\citep{grand2025self}, ReDel~\cite{zhu2024redel}, Context Folding~\citep{sun2025scalinglonghorizonllmagent}, and AgentFold~\citep{ye2025agentfoldlonghorizonwebagents} have explored deferring the choice of sub-LM calls to the LM. These techniques emphasize \textit{task} decomposition through recursive LM calls, but are unable to handle long context inputs beyond the length of the base LM. \RLM{}s, on the other hand, are enabled by an extremely simple intuition (i.e., placing the prompt in the external environment) to \textit{symbolically} manipulate arbitrarily long strings and to iteratively refine their recursion via execution feedback from the persistent REPL.
